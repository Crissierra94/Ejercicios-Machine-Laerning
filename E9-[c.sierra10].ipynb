{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9\n",
    "\n",
    "## Mashable news stories analysis\n",
    "\n",
    "Predicting if a news story is going to be popular\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>Popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2014/12/10/cia-torture-rep...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.732620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.487500</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/10/18/bitlock-kicksta...</td>\n",
       "      <td>447.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.653199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.135340</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/07/24/google-glass-po...</td>\n",
       "      <td>533.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/11/21/these-are-the-m...</td>\n",
       "      <td>413.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.497409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.677350</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.195701</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2014/02/11/parking-ticket-...</td>\n",
       "      <td>331.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  timedelta  \\\n",
       "0  http://mashable.com/2014/12/10/cia-torture-rep...       28.0   \n",
       "1  http://mashable.com/2013/10/18/bitlock-kicksta...      447.0   \n",
       "2  http://mashable.com/2013/07/24/google-glass-po...      533.0   \n",
       "3  http://mashable.com/2013/11/21/these-are-the-m...      413.0   \n",
       "4  http://mashable.com/2014/02/11/parking-ticket-...      331.0   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0             9.0             188.0         0.732620               1.0   \n",
       "1             7.0             297.0         0.653199               1.0   \n",
       "2            11.0             181.0         0.660377               1.0   \n",
       "3            12.0             781.0         0.497409               1.0   \n",
       "4             8.0             177.0         0.685714               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs   ...     \\\n",
       "0                  0.844262        5.0             1.0       1.0   ...      \n",
       "1                  0.815789        9.0             4.0       1.0   ...      \n",
       "2                  0.775701        4.0             3.0       1.0   ...      \n",
       "3                  0.677350       10.0             3.0       1.0   ...      \n",
       "4                  0.830357        3.0             2.0       1.0   ...      \n",
       "\n",
       "   min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0               0.200000                   0.80              -0.487500   \n",
       "1               0.160000                   0.50              -0.135340   \n",
       "2               0.136364                   1.00               0.000000   \n",
       "3               0.100000                   1.00              -0.195701   \n",
       "4               0.100000                   0.55              -0.175000   \n",
       "\n",
       "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                  -0.60              -0.250000                 0.9   \n",
       "1                  -0.40              -0.050000                 0.1   \n",
       "2                   0.00               0.000000                 0.3   \n",
       "3                  -0.40              -0.071429                 0.0   \n",
       "4                  -0.25              -0.100000                 0.0   \n",
       "\n",
       "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                       0.8                     0.4   \n",
       "1                      -0.1                     0.4   \n",
       "2                       1.0                     0.2   \n",
       "3                       0.0                     0.5   \n",
       "4                       0.0                     0.5   \n",
       "\n",
       "   abs_title_sentiment_polarity  Popular  \n",
       "0                           0.8        1  \n",
       "1                           0.1        0  \n",
       "2                           1.0        0  \n",
       "3                           0.0        0  \n",
       "4                           0.0        0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/albahnsen/PracticalMachineLearningClass/master/datasets/mashable.csv'\n",
    "train_df = pd.read_csv(url, index_col=0)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 61)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(['url', 'Popular'], axis=1)\n",
    "y = train_df['Popular']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.1\n",
    "\n",
    "Estimate a Decision Tree Classifier and a Logistic Regresion\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.6413333333333333\n",
      "F1 score  0.6072992700729928\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "treeclf = DecisionTreeClassifier(max_depth=3, random_state=1)\n",
    "treeclf.fit(X_train, y_train)\n",
    "y_pred = treeclf.predict(X_test)\n",
    "\n",
    "print('Accuracy ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('F1 score ',metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.6273333333333333\n",
      "F1 score  0.6104529616724739\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('Accuracy ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('F1 score ',metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.2\n",
    "\n",
    "Estimate 300 bagged samples\n",
    "\n",
    "Estimate the following set of classifiers:\n",
    "\n",
    "* 100 Decision Trees where max_depth=None\n",
    "* 100 Decision Trees where max_depth=2\n",
    "* 100 Logistic Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "n_samples = X_train.shape[0]\n",
    "n_B = 300\n",
    "\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(1, n_B +1 )]\n",
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 300\n",
    "\n",
    "np.random.seed(123) \n",
    "seeds = np.random.randint(1, 10000, size=n_estimators)\n",
    "\n",
    "trees = {}\n",
    "for i in range(100):\n",
    "    trees[i] = DecisionTreeClassifier(max_depth=None, random_state=seeds[i])\n",
    "    trees[i].fit(X_train.iloc[samples[i]], y_train.iloc[samples[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100,200):\n",
    "    trees[i] = DecisionTreeClassifier(max_depth=2, random_state=seeds[i])\n",
    "    trees[i].fit(X_train.iloc[samples[i]], y_train.iloc[samples[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200,300):\n",
    "    trees[i] = LogisticRegression(random_state=seeds[i])\n",
    "    trees[i].fit(X_train.iloc[samples[i]], y_train.iloc[samples[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.3\n",
    "\n",
    "Ensemble using majority voting\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3721</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9   ...   290  291  292  \\\n",
       "1483    1    1    0    0    1    1    1    1    1    1 ...     1    1    1   \n",
       "2185    1    1    1    1    0    1    1    1    1    0 ...     1    1    1   \n",
       "2520    1    0    0    0    1    0    1    1    0    0 ...     1    1    1   \n",
       "3721    1    1    1    0    1    0    1    1    1    1 ...     1    1    1   \n",
       "3727    0    0    0    0    1    0    1    1    0    0 ...     0    0    0   \n",
       "\n",
       "      293  294  295  296  297  298  299  \n",
       "1483    1    1    1    1    1    1    1  \n",
       "2185    1    1    1    1    1    1    1  \n",
       "2520    1    1    1    1    1    1    1  \n",
       "3721    1    1    1    1    1    1    1  \n",
       "3727    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df = pd.DataFrame(index=X_test.index, columns=list(range(n_estimators)))\n",
    "for i in range(n_estimators):\n",
    "    y_pred_df.iloc[:, i] = trees[i].predict(X_test)\n",
    "\n",
    "y_pred_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score  0.6253443526170799\n",
      "Accuracy  0.6373333333333333\n"
     ]
    }
   ],
   "source": [
    "y_pred = (y_pred_df.sum(axis=1) >= (n_estimators / 2)).astype(np.int)\n",
    "print('F1_score ', metrics.f1_score(y_pred, y_test))\n",
    "print('Accuracy ', metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.4\n",
    "\n",
    "Estimate te probability as %models that predict positive\n",
    "\n",
    "Modify the probability threshold and select the one that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>804</td>\n",
       "      <td>0.536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>696</td>\n",
       "      <td>0.464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  percentage\n",
       "0    804       0.536\n",
       "1    696       0.464"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=((y_pred_df.sum(axis=1)/n_estimators) >= 0.5).astype(np.int)\n",
    "y_pred.head()\n",
    "\n",
    "y_pred.value_counts().to_frame('count').assign(percentage = lambda x: x/x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frange(start, stop, step):\n",
    "    i = start\n",
    "    while i < stop:\n",
    "        yield i\n",
    "        i += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "F1_score  0.6702127659574468\n",
      "0.01\n",
      "F1_score  0.6705099778270509\n",
      "0.02\n",
      "F1_score  0.6714095153401511\n",
      "0.03\n",
      "F1_score  0.6738159070598748\n",
      "0.04\n",
      "F1_score  0.6753246753246753\n",
      "0.05\n",
      "F1_score  0.6780575539568344\n",
      "0.060000000000000005\n",
      "F1_score  0.6818596171376481\n",
      "0.07\n",
      "F1_score  0.6875287620800737\n",
      "0.08\n",
      "F1_score  0.6884328358208955\n",
      "0.09\n",
      "F1_score  0.6948669201520913\n",
      "0.09999999999999999\n",
      "F1_score  0.6982134234669242\n",
      "0.10999999999999999\n",
      "F1_score  0.7012732615083251\n",
      "0.11999999999999998\n",
      "F1_score  0.7058823529411765\n",
      "0.12999999999999998\n",
      "F1_score  0.7062404870624048\n",
      "0.13999999999999999\n",
      "F1_score  0.7066735644076564\n",
      "0.15\n",
      "F1_score  0.7076923076923076\n",
      "0.16\n",
      "F1_score  0.700650759219089\n",
      "0.17\n",
      "F1_score  0.6940588561910049\n",
      "0.18000000000000002\n",
      "F1_score  0.6913439635535308\n",
      "0.19000000000000003\n",
      "F1_score  0.6858789625360231\n",
      "0.20000000000000004\n",
      "F1_score  0.67953216374269\n",
      "0.21000000000000005\n",
      "F1_score  0.6784452296819788\n",
      "0.22000000000000006\n",
      "F1_score  0.6765578635014837\n",
      "0.23000000000000007\n",
      "F1_score  0.6766467065868265\n",
      "0.24000000000000007\n",
      "F1_score  0.674698795180723\n",
      "0.25000000000000006\n",
      "F1_score  0.6747279322853688\n",
      "0.26000000000000006\n",
      "F1_score  0.6715328467153284\n",
      "0.2700000000000001\n",
      "F1_score  0.6711409395973154\n",
      "0.2800000000000001\n",
      "F1_score  0.6707391569945022\n",
      "0.2900000000000001\n",
      "F1_score  0.6691131498470948\n",
      "0.3000000000000001\n",
      "F1_score  0.6674861708666258\n",
      "0.3100000000000001\n",
      "F1_score  0.6658431130327362\n",
      "0.3200000000000001\n",
      "F1_score  0.665015479876161\n",
      "0.3300000000000001\n",
      "F1_score  0.665015479876161\n",
      "0.34000000000000014\n",
      "F1_score  0.6633601983880968\n",
      "0.35000000000000014\n",
      "F1_score  0.6662515566625156\n",
      "0.36000000000000015\n",
      "F1_score  0.6649999999999999\n",
      "0.37000000000000016\n",
      "F1_score  0.6641509433962264\n",
      "0.38000000000000017\n",
      "F1_score  0.6611883691529709\n",
      "0.3900000000000002\n",
      "F1_score  0.6620164870006341\n",
      "0.4000000000000002\n",
      "F1_score  0.6598726114649681\n",
      "0.4100000000000002\n",
      "F1_score  0.6555484284797948\n",
      "0.4200000000000002\n",
      "F1_score  0.6571981923821819\n",
      "0.4300000000000002\n",
      "F1_score  0.6575698505523067\n",
      "0.4400000000000002\n",
      "F1_score  0.6526867627785059\n",
      "0.45000000000000023\n",
      "F1_score  0.6450331125827814\n",
      "0.46000000000000024\n",
      "F1_score  0.6452905811623246\n",
      "0.47000000000000025\n",
      "F1_score  0.6406984553391539\n",
      "0.48000000000000026\n",
      "F1_score  0.6358695652173914\n",
      "0.49000000000000027\n",
      "F1_score  0.6296296296296297\n",
      "0.5000000000000002\n",
      "F1_score  0.6238785369220152\n",
      "0.5100000000000002\n",
      "F1_score  0.6208333333333333\n",
      "0.5200000000000002\n",
      "F1_score  0.6194814295725297\n",
      "0.5300000000000002\n",
      "F1_score  0.615819209039548\n",
      "0.5400000000000003\n",
      "F1_score  0.6122159090909092\n",
      "0.5500000000000003\n",
      "F1_score  0.6020114942528735\n",
      "0.5600000000000003\n",
      "F1_score  0.6016023306627822\n",
      "0.5700000000000003\n",
      "F1_score  0.5973645680819912\n",
      "0.5800000000000003\n",
      "F1_score  0.5966201322556944\n",
      "0.5900000000000003\n",
      "F1_score  0.5942350332594236\n",
      "0.6000000000000003\n",
      "F1_score  0.5936343449296817\n",
      "0.6100000000000003\n",
      "F1_score  0.5909428359317002\n",
      "0.6200000000000003\n",
      "F1_score  0.5891126025354214\n",
      "0.6300000000000003\n",
      "F1_score  0.5863874345549738\n",
      "0.6400000000000003\n",
      "F1_score  0.5840840840840841\n",
      "0.6500000000000004\n",
      "F1_score  0.5840840840840841\n",
      "0.6600000000000004\n",
      "F1_score  0.5837104072398189\n",
      "0.6700000000000004\n",
      "F1_score  0.5798637395912187\n",
      "0.6800000000000004\n",
      "F1_score  0.5788271134805788\n",
      "0.6900000000000004\n",
      "F1_score  0.5775401069518716\n",
      "0.7000000000000004\n",
      "F1_score  0.5747126436781609\n",
      "0.7100000000000004\n",
      "F1_score  0.5718677940046119\n",
      "0.7200000000000004\n",
      "F1_score  0.5712086220169361\n",
      "0.7300000000000004\n",
      "F1_score  0.5665634674922602\n",
      "0.7400000000000004\n",
      "F1_score  0.5625485625485626\n",
      "0.7500000000000004\n",
      "F1_score  0.5571205007824725\n",
      "0.7600000000000005\n",
      "F1_score  0.555729984301413\n",
      "0.7700000000000005\n",
      "F1_score  0.5486166007905139\n",
      "0.7800000000000005\n",
      "F1_score  0.5463258785942492\n",
      "0.7900000000000005\n",
      "F1_score  0.540192926045016\n",
      "0.8000000000000005\n",
      "F1_score  0.5364667747163695\n",
      "0.8100000000000005\n",
      "F1_score  0.5283018867924528\n",
      "0.8200000000000005\n",
      "F1_score  0.5224625623960066\n",
      "0.8300000000000005\n",
      "F1_score  0.5076660988074957\n",
      "0.8400000000000005\n",
      "F1_score  0.4965277777777778\n",
      "0.8500000000000005\n",
      "F1_score  0.467741935483871\n",
      "0.8600000000000005\n",
      "F1_score  0.4411492122335496\n",
      "0.8700000000000006\n",
      "F1_score  0.40191387559808617\n",
      "0.8800000000000006\n",
      "F1_score  0.36036036036036034\n",
      "0.8900000000000006\n",
      "F1_score  0.3039832285115305\n",
      "0.9000000000000006\n",
      "F1_score  0.2671009771986971\n",
      "0.9100000000000006\n",
      "F1_score  0.21818181818181817\n",
      "0.9200000000000006\n",
      "F1_score  0.17798594847775176\n",
      "0.9300000000000006\n",
      "F1_score  0.1265206812652068\n",
      "0.9400000000000006\n",
      "F1_score  0.09913258983890953\n",
      "0.9500000000000006\n",
      "F1_score  0.05115089514066496\n",
      "0.9600000000000006\n",
      "F1_score  0.020887728459530026\n",
      "0.9700000000000006\n",
      "F1_score  0.0026420079260237777\n",
      "0.9800000000000006\n",
      "F1_score  0.0026420079260237777\n",
      "0.9900000000000007\n",
      "F1_score  0.0\n"
     ]
    }
   ],
   "source": [
    "for i in frange (0, 1, 0.01):\n",
    "    y_pred=((y_pred_df.sum(axis=1)/n_estimators) >= i).astype(np.int)\n",
    "    print(i)\n",
    "    print('F1_score ', metrics.f1_score(y_pred, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se escoge el umbral de 0.15 pues es el que maximiza el F1_score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.5\n",
    "\n",
    "Ensemble using weighted voting using the oob_error\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.496)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_oob = []\n",
    "for sample in samples:\n",
    "    samples_oob.append(sorted(set(range(n_samples)) - set(sample)))\n",
    "\n",
    "errors = np.zeros(n_estimators)\n",
    "\n",
    "for i in range(n_estimators):\n",
    "    y_pred_ = trees[i].predict(X_train.iloc[samples_oob[i]])\n",
    "    errors[i] = 1 - metrics.accuracy_score(y_train.iloc[samples_oob[i]], y_pred_)\n",
    "    \n",
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.6\n",
    "\n",
    "Estimate te probability of the weighted voting\n",
    "\n",
    "Modify the probability threshold and select the one that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "F1_score  0.6702127659574468\n",
      "0.01\n",
      "F1_score  0.6705099778270509\n",
      "0.02\n",
      "F1_score  0.6723063223508459\n",
      "0.03\n",
      "F1_score  0.6741171211443898\n",
      "0.04\n",
      "F1_score  0.6765365634813818\n",
      "0.05\n",
      "F1_score  0.6787330316742081\n",
      "0.060000000000000005\n",
      "F1_score  0.6852954649564819\n",
      "0.07\n",
      "F1_score  0.6911286576869484\n",
      "0.08\n",
      "F1_score  0.6931442080378252\n",
      "0.09\n",
      "F1_score  0.6981222917669715\n",
      "0.09999999999999999\n",
      "F1_score  0.7018572825024438\n",
      "0.10999999999999999\n",
      "F1_score  0.7055306427503737\n",
      "0.11999999999999998\n",
      "F1_score  0.7058823529411765\n",
      "0.12999999999999998\n",
      "F1_score  0.7067357512953368\n",
      "0.13999999999999999\n",
      "F1_score  0.7060702875399362\n",
      "0.15\n",
      "F1_score  0.7008174386920981\n",
      "0.16\n",
      "F1_score  0.6937639198218263\n",
      "0.17\n",
      "F1_score  0.6905574516496018\n",
      "0.18000000000000002\n",
      "F1_score  0.6847575057736721\n",
      "0.19000000000000003\n",
      "F1_score  0.6799065420560747\n",
      "0.20000000000000004\n",
      "F1_score  0.6768687463213655\n",
      "0.21000000000000005\n",
      "F1_score  0.6773428232502966\n",
      "0.22000000000000006\n",
      "F1_score  0.6750298685782556\n",
      "0.23000000000000007\n",
      "F1_score  0.6762936221419975\n",
      "0.24000000000000007\n",
      "F1_score  0.6731234866828087\n",
      "0.25000000000000006\n",
      "F1_score  0.6731470230862698\n",
      "0.26000000000000006\n",
      "F1_score  0.6715417428397318\n",
      "0.2700000000000001\n",
      "F1_score  0.6707391569945022\n",
      "0.2800000000000001\n",
      "F1_score  0.6691131498470948\n",
      "0.2900000000000001\n",
      "F1_score  0.6678921568627452\n",
      "0.3000000000000001\n",
      "F1_score  0.6658461538461538\n",
      "0.3100000000000001\n",
      "F1_score  0.6650185414091471\n",
      "0.3200000000000001\n",
      "F1_score  0.665015479876161\n",
      "0.3300000000000001\n",
      "F1_score  0.6641883519206939\n",
      "0.34000000000000014\n",
      "F1_score  0.6641837368094352\n",
      "0.35000000000000014\n",
      "F1_score  0.6662515566625156\n",
      "0.36000000000000015\n",
      "F1_score  0.6649999999999999\n",
      "0.37000000000000016\n",
      "F1_score  0.6628859483301828\n",
      "0.38000000000000017\n",
      "F1_score  0.6611883691529709\n",
      "0.3900000000000002\n",
      "F1_score  0.6611675126903553\n",
      "0.4000000000000002\n",
      "F1_score  0.6590184831102612\n",
      "0.4100000000000002\n",
      "F1_score  0.6585522101217168\n",
      "0.4200000000000002\n",
      "F1_score  0.6571981923821819\n",
      "0.4300000000000002\n",
      "F1_score  0.6571428571428571\n",
      "0.4400000000000002\n",
      "F1_score  0.6518032786885246\n",
      "0.45000000000000023\n",
      "F1_score  0.6455026455026455\n",
      "0.46000000000000024\n",
      "F1_score  0.643524699599466\n",
      "0.47000000000000025\n",
      "F1_score  0.6411290322580645\n",
      "0.48000000000000026\n",
      "F1_score  0.6359322033898305\n",
      "0.49000000000000027\n",
      "F1_score  0.6297056810403834\n",
      "0.5000000000000002\n",
      "F1_score  0.6253443526170799\n",
      "0.5100000000000002\n",
      "F1_score  0.6231783483691882\n",
      "0.5200000000000002\n",
      "F1_score  0.6194814295725297\n",
      "0.5300000000000002\n",
      "F1_score  0.6153846153846154\n",
      "0.5400000000000003\n",
      "F1_score  0.6102418207681366\n",
      "0.5500000000000003\n",
      "F1_score  0.6024442846872754\n",
      "0.5600000000000003\n",
      "F1_score  0.6005830903790088\n",
      "0.5700000000000003\n",
      "F1_score  0.5969275786393563\n",
      "0.5800000000000003\n",
      "F1_score  0.5966201322556944\n",
      "0.5900000000000003\n",
      "F1_score  0.5933579335793359\n",
      "0.6000000000000003\n",
      "F1_score  0.5925925925925926\n",
      "0.6100000000000003\n",
      "F1_score  0.5898959881129273\n",
      "0.6200000000000003\n",
      "F1_score  0.5907738095238095\n",
      "0.6300000000000003\n",
      "F1_score  0.5874439461883407\n",
      "0.6400000000000003\n",
      "F1_score  0.5847076461769115\n",
      "0.6500000000000004\n",
      "F1_score  0.5840840840840841\n",
      "0.6600000000000004\n",
      "F1_score  0.5819548872180451\n",
      "0.6700000000000004\n",
      "F1_score  0.5804988662131519\n",
      "0.6800000000000004\n",
      "F1_score  0.5807429871114481\n",
      "0.6900000000000004\n",
      "F1_score  0.5792682926829269\n",
      "0.7000000000000004\n",
      "F1_score  0.5758039816232772\n",
      "0.7100000000000004\n",
      "F1_score  0.5725249424405219\n",
      "0.7200000000000004\n",
      "F1_score  0.5707692307692308\n",
      "0.7300000000000004\n",
      "F1_score  0.5679012345679013\n",
      "0.7400000000000004\n",
      "F1_score  0.5643410852713178\n",
      "0.7500000000000004\n",
      "F1_score  0.56298600311042\n",
      "0.7600000000000005\n",
      "F1_score  0.5582486317435497\n",
      "0.7700000000000005\n",
      "F1_score  0.5534591194968553\n",
      "0.7800000000000005\n",
      "F1_score  0.5494853523357087\n",
      "0.7900000000000005\n",
      "F1_score  0.546613545816733\n",
      "0.8000000000000005\n",
      "F1_score  0.5385852090032154\n",
      "0.8100000000000005\n",
      "F1_score  0.5335489086499595\n",
      "0.8200000000000005\n",
      "F1_score  0.5270935960591133\n",
      "0.8300000000000005\n",
      "F1_score  0.5249169435215947\n",
      "0.8400000000000005\n",
      "F1_score  0.5106022052586938\n",
      "0.8500000000000005\n",
      "F1_score  0.4969801553062985\n",
      "0.8600000000000005\n",
      "F1_score  0.4715302491103202\n",
      "0.8700000000000006\n",
      "F1_score  0.44362292051756\n",
      "0.8800000000000006\n",
      "F1_score  0.40191387559808617\n",
      "0.8900000000000006\n",
      "F1_score  0.3587174348697395\n",
      "0.9000000000000006\n",
      "F1_score  0.30220356768100737\n",
      "0.9100000000000006\n",
      "F1_score  0.2676822633297062\n",
      "0.9200000000000006\n",
      "F1_score  0.20642201834862384\n",
      "0.9300000000000006\n",
      "F1_score  0.1635071090047393\n",
      "0.9400000000000006\n",
      "F1_score  0.11519607843137254\n",
      "0.9500000000000006\n",
      "F1_score  0.08281053952321205\n",
      "0.9600000000000006\n",
      "F1_score  0.026007802340702206\n",
      "0.9700000000000006\n",
      "F1_score  0.005277044854881266\n",
      "0.9800000000000006\n",
      "F1_score  0.0026420079260237777\n",
      "0.9900000000000007\n",
      "F1_score  0.0026420079260237777\n"
     ]
    }
   ],
   "source": [
    "alpha = (1 - errors) / (1 - errors).sum()\n",
    "weighted_sum_1 = ((y_pred_df) * alpha).sum(axis=1)\n",
    "y_pred = (weighted_sum_1 >= 0.5).astype(np.int)\n",
    "y_pred.head()\n",
    "\n",
    "for i in frange (0, 1, 0.01):\n",
    "    y_pred = (weighted_sum_1 >= i).astype(np.int)\n",
    "    print(i)\n",
    "    print('F1_score ', metrics.f1_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se elige el 0.13 como umbral que maximiza el F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.7\n",
    "\n",
    "Estimate a logistic regression using as input the estimated classifiers\n",
    "\n",
    "Modify the probability threshold such that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6425755584756899 0.6373333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2 = pd.DataFrame(index=X_train.index, columns=list(range(n_estimators)))\n",
    "\n",
    "for i in range(n_estimators):\n",
    "    X_train_2[i] = trees[i].predict(X_train)\n",
    "    \n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "lr = LogisticRegressionCV(cv = 5, random_state=123)\n",
    "lr.fit(X_train_2, y_train)\n",
    "\n",
    "y_pred = lr.predict(y_pred_df)\n",
    "\n",
    "print(metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test))\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0.6702127659574468]\n",
      "[0.01, 0.6702127659574468]\n",
      "[0.02, 0.6702127659574468]\n",
      "[0.03, 0.6714095153401511]\n",
      "[0.04, 0.6741171211443898]\n",
      "[0.05, 0.6762331838565023]\n",
      "[0.060000000000000005, 0.6792792792792792]\n",
      "[0.07, 0.6805807622504538]\n",
      "[0.08, 0.6834631241410902]\n",
      "[0.09, 0.6870937790157846]\n",
      "[0.09999999999999999, 0.6877912395153775]\n",
      "[0.10999999999999999, 0.6890042472864558]\n",
      "[0.11999999999999998, 0.6913932477413219]\n",
      "[0.12999999999999998, 0.6925659472422062]\n",
      "[0.13999999999999999, 0.6956102267245537]\n",
      "[0.15, 0.6971762414800389]\n",
      "[0.16, 0.7]\n",
      "[0.17, 0.70262246412667]\n",
      "[0.18000000000000002, 0.7048853439680957]\n",
      "[0.19000000000000003, 0.7040560841261893]\n",
      "[0.20000000000000004, 0.7055863110216406]\n",
      "[0.21000000000000005, 0.7070707070707071]\n",
      "[0.22000000000000006, 0.7080366225839267]\n",
      "[0.23000000000000007, 0.7081192189105858]\n",
      "[0.24000000000000007, 0.708612686952037]\n",
      "[0.25000000000000006, 0.7088738972496108]\n",
      "[0.26000000000000006, 0.7078534031413612]\n",
      "[0.2700000000000001, 0.7056345444971037]\n",
      "[0.2800000000000001, 0.7034482758620689]\n",
      "[0.2900000000000001, 0.6988210075026795]\n",
      "[0.3000000000000001, 0.6971490048413125]\n",
      "[0.3100000000000001, 0.6972176759410803]\n",
      "[0.3200000000000001, 0.6912899669239251]\n",
      "[0.3300000000000001, 0.6929046563192904]\n",
      "[0.34000000000000014, 0.6948198198198198]\n",
      "[0.35000000000000014, 0.6954055587067499]\n",
      "[0.36000000000000015, 0.6946039035591275]\n",
      "[0.37000000000000016, 0.6917293233082707]\n",
      "[0.38000000000000017, 0.691588785046729]\n",
      "[0.3900000000000002, 0.6929411764705882]\n",
      "[0.4000000000000002, 0.6841165972635336]\n",
      "[0.4100000000000002, 0.681081081081081]\n",
      "[0.4200000000000002, 0.6791314837153196]\n",
      "[0.4300000000000002, 0.6723507917174177]\n",
      "[0.4400000000000002, 0.6683016554261189]\n",
      "[0.45000000000000023, 0.6641837368094352]\n",
      "[0.46000000000000024, 0.6620428751576292]\n",
      "[0.47000000000000025, 0.6581956797966962]\n",
      "[0.48000000000000026, 0.6529562982005143]\n",
      "[0.49000000000000027, 0.6511024643320363]\n",
      "[0.5000000000000002, 0.6425755584756899]\n",
      "[0.5100000000000002, 0.6436170212765957]\n",
      "[0.5200000000000002, 0.6397849462365591]\n",
      "[0.5300000000000002, 0.6355013550135501]\n",
      "[0.5400000000000003, 0.6334470989761092]\n",
      "[0.5500000000000003, 0.63216011042098]\n",
      "[0.5600000000000003, 0.6249130132219903]\n",
      "[0.5700000000000003, 0.6204946996466433]\n",
      "[0.5800000000000003, 0.6135231316725979]\n",
      "[0.5900000000000003, 0.6067577282530553]\n",
      "[0.6000000000000003, 0.6014492753623188]\n",
      "[0.6100000000000003, 0.5930831493745401]\n",
      "[0.6200000000000003, 0.5905044510385756]\n",
      "[0.6300000000000003, 0.5789871504157218]\n",
      "[0.6400000000000003, 0.5712098009188362]\n",
      "[0.6500000000000004, 0.5656877897990726]\n",
      "[0.6600000000000004, 0.5598123534010946]\n",
      "[0.6700000000000004, 0.5522151898734177]\n",
      "[0.6800000000000004, 0.5488]\n",
      "[0.6900000000000004, 0.5286415711947627]\n",
      "[0.7000000000000004, 0.5158069883527454]\n",
      "[0.7100000000000004, 0.5104602510460251]\n",
      "[0.7200000000000004, 0.49872340425531914]\n",
      "[0.7300000000000004, 0.49222797927461137]\n",
      "[0.7400000000000004, 0.48251748251748255]\n",
      "[0.7500000000000004, 0.46249999999999997]\n",
      "[0.7600000000000005, 0.4509090909090909]\n",
      "[0.7700000000000005, 0.4487179487179487]\n",
      "[0.7800000000000005, 0.43085606773283164]\n",
      "[0.7900000000000005, 0.40882917466410745]\n",
      "[0.8000000000000005, 0.38986354775828463]\n",
      "[0.8100000000000005, 0.37264618434093155]\n",
      "[0.8200000000000005, 0.3455284552845528]\n",
      "[0.8300000000000005, 0.3295336787564767]\n",
      "[0.8400000000000005, 0.3136842105263158]\n",
      "[0.8500000000000005, 0.291220556745182]\n",
      "[0.8600000000000005, 0.252212389380531]\n",
      "[0.8700000000000006, 0.23595505617977527]\n",
      "[0.8800000000000006, 0.21305841924398625]\n",
      "[0.8900000000000006, 0.17969661610268378]\n",
      "[0.9000000000000006, 0.1521997621878716]\n",
      "[0.9100000000000006, 0.13734939759036144]\n",
      "[0.9200000000000006, 0.1150550795593635]\n",
      "[0.9300000000000006, 0.0898876404494382]\n",
      "[0.9400000000000006, 0.05357142857142857]\n",
      "[0.9500000000000006, 0.025974025974025972]\n",
      "[0.9600000000000006, 0.005270092226613965]\n",
      "[0.9700000000000006, 0.0026420079260237777]\n",
      "[0.9800000000000006, 0.0]\n",
      "[0.9900000000000007, 0.0]\n"
     ]
    }
   ],
   "source": [
    "for i in frange (0, 1, 0.01):\n",
    "    y_pred = np.where(lr.predict_proba(y_pred_df)[:,1] >= i, 1, 0)\n",
    "    print(([ i, metrics.f1_score(y_pred, y_test)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El umbral que maximiza el f1_score es 0.25 con un f1_score de 0,7088."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
