{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6\n",
    "\n",
    "## SVM & Regularization\n",
    "\n",
    "\n",
    "For this homework we consider a set of observations on a number of red and white wine varieties involving their chemical properties and ranking by tasters. Wine industry shows a recent growth spurt as social drinking is on the rise. The price of wine depends on a rather abstract concept of wine appreciation by wine tasters, opinion among whom may have a high degree of variability. Pricing of wine depends on such a volatile factor to some extent. Another key factor in wine certification and quality assessment is physicochemical tests which are laboratory-based and takes into account factors like acidity, pH level, presence of sugar and other chemical properties. For the wine market, it would be of interest if human quality of tasting can be related to the chemical properties of wine so that certification and quality assessment and assurance process is more controlled.\n",
    "\n",
    "Two datasets are available of which one dataset is on red wine and have 1599 different varieties and the other is on white wine and have 4898 varieties. All wines are produced in a particular area of Portugal. Data are collected on 12 different properties of the wines one of which is Quality, based on sensory data, and the rest are on chemical properties of the wines including density, acidity, alcohol content etc. All chemical properties of wines are continuous variables. Quality is an ordinal variable with possible ranking from 1 (worst) to 10 (best). Each variety of wine is tasted by three independent tasters and the final rank assigned is the median rank given by the tasters.\n",
    "\n",
    "A predictive model developed on this data is expected to provide guidance to vineyards regarding quality and price expected on their produce without heavy reliance on volatility of wine tasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r = pd.read_csv('https://github.com/albahnsen/PracticalMachineLearningClass/raw/master/datasets/Wine_data_red.csv')\n",
    "data_w = pd.read_csv('https://github.com/albahnsen/PracticalMachineLearningClass/raw/master/datasets/Wine_data_white.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.052</td>\n",
       "      <td>40.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.1</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.027</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.9897</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.31</td>\n",
       "      <td>10.8</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.075</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.61</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>5.3</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.07</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.043</td>\n",
       "      <td>34.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.57</td>\n",
       "      <td>9.7</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5382</th>\n",
       "      <td>10.6</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.68</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.114</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.66</td>\n",
       "      <td>13.4</td>\n",
       "      <td>6</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "736             6.6              0.25         0.30            14.4      0.052   \n",
       "3119            5.9              0.19         0.37             0.8      0.027   \n",
       "5302            7.7              0.69         0.05             2.7      0.075   \n",
       "267             5.3              0.58         0.07             6.9      0.043   \n",
       "5382           10.6              0.44         0.68             4.1      0.114   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "736                  40.0                 183.0   0.9980  3.02       0.50   \n",
       "3119                  3.0                  21.0   0.9897  3.09       0.31   \n",
       "5302                 15.0                  27.0   0.9974  3.26       0.61   \n",
       "267                  34.0                 149.0   0.9944  3.34       0.57   \n",
       "5382                  6.0                  24.0   0.9970  3.06       0.66   \n",
       "\n",
       "      alcohol  quality   type  \n",
       "736       9.1        6  white  \n",
       "3119     10.8        5  white  \n",
       "5302      9.1        5    red  \n",
       "267       9.7        5  white  \n",
       "5382     13.4        6    red  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_w.assign(type = 'white')\n",
    "\n",
    "data = data.append(data_r.assign(type = 'red'), ignore_index=True)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.1\n",
    "\n",
    "Show the frecuency table of the quality by type of wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>quality</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>red</th>\n",
       "      <td>10</td>\n",
       "      <td>53</td>\n",
       "      <td>681</td>\n",
       "      <td>638</td>\n",
       "      <td>199</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>20</td>\n",
       "      <td>163</td>\n",
       "      <td>1457</td>\n",
       "      <td>2198</td>\n",
       "      <td>880</td>\n",
       "      <td>175</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "quality   3    4     5     6    7    8  9\n",
       "type                                     \n",
       "red      10   53   681   638  199   18  0\n",
       "white    20  163  1457  2198  880  175  5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[\"type\",\"quality\"]].pivot_table(index=\"type\", columns=\"quality\", aggfunc=len, fill_value = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.2\n",
    "\n",
    "* Standarized the features (not the quality)\n",
    "* Create a binary target for each type of wine\n",
    "* Create two Linear SVM's for the white and red wines, repectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>type</th>\n",
       "      <th>quality2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality   type  quality2  \n",
       "0      8.8        6  white      True  \n",
       "1      9.5        6  white      True  \n",
       "2     10.1        6  white      True  \n",
       "3      9.9        6  white      True  \n",
       "4      9.9        6  white      True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data['quality2'] = data['quality'] > 5\n",
    "data_red = data[data['type']==\"red\"]\n",
    "data_white = data[data['type']==\"white\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.3\n",
    "\n",
    "Test the two SVM's using the different kernels (‘poly’, ‘rbf’, ‘sigmoid’)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.svm import SVC # \"Support Vector Classifier\"\n",
    "\n",
    "y =  data_red['quality2']\n",
    "X = data_red.drop(['quality','type', 'quality2'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: Poly\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.71      0.72      0.71       152\n",
      "       True       0.74      0.74      0.74       168\n",
      "\n",
      "avg / total       0.73      0.73      0.73       320\n",
      "\n",
      "0.728125\n"
     ]
    }
   ],
   "source": [
    "std_X = preprocessing.scale(X_train)\n",
    "\n",
    "clf = SVC(kernel='poly')\n",
    "clf.fit(std_X, y_train)\n",
    "y_pred = clf.predict(preprocessing.scale(X_test))  \n",
    "print(\"Kernel: Poly\\n\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: Rbf\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.69      0.72      0.70       152\n",
      "       True       0.73      0.70      0.72       168\n",
      "\n",
      "avg / total       0.71      0.71      0.71       320\n",
      "\n",
      "0.709375\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(std_X, y_train)\n",
    "y_pred = clf.predict(preprocessing.scale(X_test))  \n",
    "print(\"Kernel: Rbf\\n\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: Sigmoid\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.65      0.65      0.65       152\n",
      "       True       0.68      0.68      0.68       168\n",
      "\n",
      "avg / total       0.67      0.67      0.67       320\n",
      "\n",
      "0.66875\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='sigmoid')\n",
    "clf.fit(std_X, y_train)\n",
    "y_pred = clf.predict(preprocessing.scale(X_test))  \n",
    "print(\"Kernel: Sigmoid\\n\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =  data_white['quality2']\n",
    "X = data_white.drop(['quality','type', 'quality2'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
    "std_X = preprocessing.scale(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: Poly\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.78      0.33      0.47       328\n",
      "       True       0.74      0.95      0.83       652\n",
      "\n",
      "avg / total       0.75      0.74      0.71       980\n",
      "\n",
      "0.7448979591836735\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='poly')\n",
    "clf.fit(std_X, y_train)\n",
    "y_pred = clf.predict(preprocessing.scale(X_test))  \n",
    "print(\"Kernel: Poly\\n\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: Rbf\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.55      0.64       328\n",
      "       True       0.80      0.92      0.86       652\n",
      "\n",
      "avg / total       0.79      0.79      0.78       980\n",
      "\n",
      "0.7938775510204081\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(std_X, y_train)\n",
    "y_pred = clf.predict(preprocessing.scale(X_test))  \n",
    "print(\"Kernel: Rbf\\n\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: Sigmoid\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.47      0.45      0.46       328\n",
      "       True       0.73      0.74      0.74       652\n",
      "\n",
      "avg / total       0.64      0.65      0.64       980\n",
      "\n",
      "0.6459183673469387\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='sigmoid')\n",
    "clf.fit(std_X, y_train)\n",
    "y_pred = clf.predict(preprocessing.scale(X_test))  \n",
    "print(\"Kernel: Sigmoid\\n\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.4\n",
    "Using the best SVM find the parameters that gives the best performance\n",
    "\n",
    "'C': [0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametro C:  0.1\n",
      "Parametro gamma:  0.01\n",
      "Accuracy:  0.6928571428571428\n",
      "Parametro C:  0.1\n",
      "Parametro gamma:  0.001\n",
      "Accuracy:  0.6489795918367347\n",
      "Parametro C:  0.1\n",
      "Parametro gamma:  0.0001\n",
      "Accuracy:  0.6489795918367347\n",
      "Parametro C:  1\n",
      "Parametro gamma:  0.01\n",
      "Accuracy:  0.7520408163265306\n",
      "Parametro C:  1\n",
      "Parametro gamma:  0.001\n",
      "Accuracy:  0.689795918367347\n",
      "Parametro C:  1\n",
      "Parametro gamma:  0.0001\n",
      "Accuracy:  0.6489795918367347\n",
      "Parametro C:  10\n",
      "Parametro gamma:  0.01\n",
      "Accuracy:  0.7612244897959184\n",
      "Parametro C:  10\n",
      "Parametro gamma:  0.001\n",
      "Accuracy:  0.7448979591836735\n",
      "Parametro C:  10\n",
      "Parametro gamma:  0.0001\n",
      "Accuracy:  0.6908163265306122\n",
      "Parametro C:  100\n",
      "Parametro gamma:  0.01\n",
      "Accuracy:  0.763265306122449\n",
      "Parametro C:  100\n",
      "Parametro gamma:  0.001\n",
      "Accuracy:  0.7510204081632653\n",
      "Parametro C:  100\n",
      "Parametro gamma:  0.0001\n",
      "Accuracy:  0.7387755102040816\n",
      "Parametro C:  1000\n",
      "Parametro gamma:  0.01\n",
      "Accuracy:  0.7642857142857142\n",
      "Parametro C:  1000\n",
      "Parametro gamma:  0.001\n",
      "Accuracy:  0.7591836734693878\n",
      "Parametro C:  1000\n",
      "Parametro gamma:  0.0001\n",
      "Accuracy:  0.7489795918367347\n"
     ]
    }
   ],
   "source": [
    "C=[ 0.1, 1, 10, 100, 1000]\n",
    "gamma=[0.01, 0.001, 0.0001]\n",
    "\n",
    "y_r =  data_red['quality2']\n",
    "X_r = data_red.drop(['quality','type', 'quality2'], axis=1)\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_r, y_r, test_size = 0.20)  \n",
    "\n",
    "y_w =  data_white['quality2']\n",
    "X_w = data_white.drop(['quality','type', 'quality2'], axis=1)\n",
    "X_train_w, X_test_w, y_train_w, y_test_w = train_test_split(X_w, y_w, test_size = 0.20)\n",
    "\n",
    "std_X_w = preprocessing.scale(X_train_w)\n",
    "for c in C:\n",
    "    for g in gamma:\n",
    "        clf = SVC(kernel='rbf',degree=7,C=c,gamma=g)\n",
    "        clf.fit(std_X_w, y_train_w)\n",
    "        y_pred_w = clf.predict(preprocessing.scale(X_test_w))  \n",
    "        print(\"Parametro C: \",c)\n",
    "        print(\"Parametro gamma: \",g)\n",
    "        print(\"Accuracy: \",accuracy_score(y_test_w,y_pred_w))  \n",
    "       # print(classification_report(y_test_w,y_pred_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso del vino blanco, se utiliza el kernel 'rbf' y se encuentra que los parámetros que generan mejor desempeño son: C = 1000 y gamma = 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametro C:  0.1\n",
      "Parametro gamma:  0.01\n",
      "Accuracy:  0.746875\n",
      "Parametro C:  0.1\n",
      "Parametro gamma:  0.001\n",
      "Accuracy:  0.540625\n",
      "Parametro C:  0.1\n",
      "Parametro gamma:  0.0001\n",
      "Accuracy:  0.540625\n",
      "Parametro C:  1\n",
      "Parametro gamma:  0.01\n",
      "Accuracy:  0.765625\n",
      "Parametro C:  1\n",
      "Parametro gamma:  0.001\n",
      "Accuracy:  0.74375\n",
      "Parametro C:  1\n",
      "Parametro gamma:  0.0001\n",
      "Accuracy:  0.540625\n",
      "Parametro C:  10\n",
      "Parametro gamma:  0.01\n",
      "Accuracy:  0.765625\n",
      "Parametro C:  10\n",
      "Parametro gamma:  0.001\n",
      "Accuracy:  0.759375\n",
      "Parametro C:  10\n",
      "Parametro gamma:  0.0001\n",
      "Accuracy:  0.74375\n",
      "Parametro C:  100\n",
      "Parametro gamma:  0.01\n",
      "Accuracy:  0.76875\n",
      "Parametro C:  100\n",
      "Parametro gamma:  0.001\n",
      "Accuracy:  0.753125\n",
      "Parametro C:  100\n",
      "Parametro gamma:  0.0001\n",
      "Accuracy:  0.753125\n",
      "Parametro C:  1000\n",
      "Parametro gamma:  0.01\n",
      "Accuracy:  0.796875\n",
      "Parametro C:  1000\n",
      "Parametro gamma:  0.001\n",
      "Accuracy:  0.7625\n",
      "Parametro C:  1000\n",
      "Parametro gamma:  0.0001\n",
      "Accuracy:  0.765625\n"
     ]
    }
   ],
   "source": [
    "std_X_r = preprocessing.scale(X_train_r)\n",
    "for c in C:\n",
    "    for g in gamma:\n",
    "        clf = SVC(kernel='rbf',degree=7,C=c,gamma=g)\n",
    "        clf.fit(std_X_r, y_train_r)\n",
    "        y_pred_r = clf.predict(preprocessing.scale(X_test_r))  \n",
    "        print(\"Parametro C: \",c)\n",
    "        print(\"Parametro gamma: \",g)\n",
    "        print(\"Accuracy: \",accuracy_score(y_test_r,y_pred_r))  \n",
    "       # print(classification_report(y_test_w,y_pred_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.5\n",
    "\n",
    "Compare the results with other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.01172761e-01 -5.50638295e+00  2.88424205e-01  4.88418172e-02\n",
      "  -4.32367411e-01  1.33369069e-02 -3.85570445e-03 -2.48427106e+00\n",
      "  -6.34930606e-01  1.14567841e+00  9.38654714e-01]]\n",
      "Accuracy:  0.7591836734693878\n",
      "f1 score:  0.8287373004354137\n",
      "[[-0.00309141 -2.67589309 -0.72183535  0.01010696 -1.33735789  0.03713407\n",
      "  -0.02325091 -1.0386632  -1.76800114  1.93727826  0.8735114 ]]\n",
      "Accuracy:  0.721875\n",
      "f1 score:  0.729483282674772\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train_w, y_train_w)\n",
    "y_pred_w = logreg.predict(X_test_w)\n",
    "print(logreg.coef_)\n",
    "print(\"Accuracy: \",accuracy_score(y_test_w,y_pred_w))\n",
    "print(\"f1 score: \",f1_score(y_test_w,y_pred_w))\n",
    "\n",
    "logreg.fit(X_train_r, y_train_r)\n",
    "y_pred_r = logreg.predict(X_test_r)\n",
    "print(logreg.coef_)\n",
    "print(\"Accuracy: \",accuracy_score(y_test_r,y_pred_r))\n",
    "print(\"f1 score: \",f1_score(y_test_r,y_pred_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al utilizar un modelo de regresión logística se obtiene que, en el caso del vino blanco, el resultado tiene mayor precisión utilizando SVM mientras que para el vino tinto, tiene mayor precisión el modelo de regresión logística.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.6\n",
    "\n",
    "\n",
    "* Train a linear regression to predict wine quality (Continous)\n",
    "\n",
    "* Analyze the coefficients\n",
    "\n",
    "* Evaluate the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.87881988e-02 -1.28602726e+00 -9.01442263e-02  4.41014354e-02\n",
      " -5.24707457e-01  6.43018676e-03 -2.42265299e-03 -6.54145838e+01\n",
      "  4.59238536e-01  7.76986647e-01  2.56883012e-01]\n",
      "RMSE: 0.7492115737970361\n",
      "['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "y =  data['quality']\n",
    "X = data.drop(['quality','type', 'quality2'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)  \n",
    "\n",
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_test)\n",
    "print(linreg.coef_)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print(list(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.7\n",
    "\n",
    "* Estimate a ridge regression with alpha equals 0.1 and 1.\n",
    "* Compare the coefficients with the linear regression\n",
    "* Evaluate the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7516526097330757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3.28670584e-02, -1.14429320e+00,  3.44173462e-02,  2.50056860e-02,\n",
       "       -1.04936858e+00,  5.00919910e-03, -1.74294551e-03, -3.50102676e+01,\n",
       "        2.46528658e-01,  6.49967615e-01,  2.56662584e-01])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridgereg = Ridge(alpha=0.1, normalize=True)\n",
    "ridgereg.fit(X_train, y_train)\n",
    "y_pred = ridgereg.predict(X_test)\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "ridgereg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, se observa una reducción en la magnitud de los coeficientes al aplicar la ridge regresión con respecto a la regresión lineal anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7840037650695478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 7.53905132e-05, -5.79585252e-01,  1.82874511e-01,  4.80181550e-03,\n",
       "       -1.33815551e+00,  1.78811662e-03, -5.33721132e-04, -2.47755484e+01,\n",
       "        8.16162403e-02,  2.97054409e-01,  1.38919852e-01])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridgereg = Ridge(alpha=1, normalize=True)\n",
    "ridgereg.fit(X_train, y_train)\n",
    "y_pred = ridgereg.predict(X_test)\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "ridgereg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.8\n",
    "\n",
    "* Estimate a lasso regression with alpha equals 0.01, 0.1 and 1.\n",
    "* Compare the coefficients with the linear regression\n",
    "* Evaluate the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.25176256e-04 -8.95711656e-01  0.00000000e+00  1.63531443e-02\n",
      " -0.00000000e+00  7.09433568e-03 -2.00412840e-03 -0.00000000e+00\n",
      "  0.00000000e+00  1.45701115e-02  3.36024110e-01]\n",
      "0.758860434170095\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lassoreg = Lasso(alpha=0.01, normalize=False)\n",
    "lassoreg.fit(X_train, y_train)\n",
    "y_pred = lassoreg.predict(X_test)\n",
    "\n",
    "print(lassoreg.coef_)\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.         -0.          0.          0.00560169 -0.          0.00775869\n",
      " -0.00093088 -0.         -0.          0.          0.2771603 ]\n",
      "0.7883868704348472\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lassoreg = Lasso(alpha=0.1, normalize=False)\n",
    "lassoreg.fit(X_train, y_train)\n",
    "y_pred = lassoreg.predict(X_test)\n",
    "\n",
    "print(lassoreg.coef_)\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.         -0.          0.         -0.         -0.          0.0008104\n",
      " -0.00040419 -0.          0.          0.          0.        ]\n",
      "0.8724987119586692\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lassoreg = Lasso(alpha=1, normalize=False)\n",
    "lassoreg.fit(X_train, y_train)\n",
    "y_pred = lassoreg.predict(X_test)\n",
    "\n",
    "print(lassoreg.coef_)\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La \n",
    "regresión lasso genera coeficientes aun más suavizados que la regresión ridge, con respecto a la lineal. En particular, se oobserva que a mayor alpha, los coeficientes se reducen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.9\n",
    "\n",
    "* Create a binary target\n",
    "\n",
    "* Train a logistic regression to predict wine quality (binary)\n",
    "\n",
    "* Analyze the coefficients\n",
    "\n",
    "* Evaluate the f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02107634 -4.02894716 -0.58016863  0.05689132 -1.52035686  0.01727209\n",
      "  -0.00845489 -3.39855554 -0.11914079  1.82950374  0.84410775]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.810344827586207"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "y = data['quality2']\n",
    "X = data.drop(['quality','type', 'quality2'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20) \n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(logreg.coef_)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.10\n",
    "\n",
    "* Estimate a regularized logistic regression using:\n",
    "* C = 0.01, 0.1 & 1.0\n",
    "* penalty = ['l1, 'l2']\n",
    "* Compare the coefficients and the f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01980796 -0.67719415 -0.06650948  0.26926473 -0.08056314  0.27075642\n",
      "  -0.40108407  0.          0.07391007  0.28762564  1.04147213]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "logreg = LogisticRegression(C=0.1, penalty='l1',solver='liblinear')\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "print(logreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametro C:  0.01\n",
      "Penalty:  l1\n",
      "[[ 0.         -0.4715298   0.          0.05028495  0.          0.\n",
      "  -0.01380268  0.          0.          0.12599567  0.85891715]]\n",
      "Accuracy:  0.7423076923076923\n",
      "F1 score:  0.8057971014492753\n",
      "Parametro C:  0.01\n",
      "Penalty:  l2\n",
      "[[ 0.07676207 -0.55250823 -0.03714039  0.27837915 -0.10889693  0.21754247\n",
      "  -0.32994422 -0.15708738  0.10794533  0.26875093  0.80334581]]\n",
      "Accuracy:  0.7484615384615385\n",
      "F1 score:  0.8104347826086956\n",
      "Parametro C:  0.1\n",
      "Penalty:  l1\n",
      "[[ 0.01981395 -0.67717652 -0.06651255  0.26924605 -0.0805422   0.27071666\n",
      "  -0.4010074   0.          0.07391683  0.28761124  1.04148349]]\n",
      "Accuracy:  0.7484615384615385\n",
      "F1 score:  0.811527377521614\n",
      "Parametro C:  0.1\n",
      "Penalty:  l2\n",
      "[[ 0.09778954 -0.67977    -0.08566517  0.35213997 -0.0881744   0.29727818\n",
      "  -0.43424601 -0.11924105  0.11948656  0.31219682  0.98767491]]\n",
      "Accuracy:  0.7453846153846154\n",
      "F1 score:  0.8087810514153667\n",
      "Parametro C:  1.0\n",
      "Penalty:  l1\n",
      "[[ 0.07631949 -0.70302944 -0.09104198  0.3325842  -0.08598832  0.30645077\n",
      "  -0.44369008 -0.06426245  0.10647456  0.31127598  1.03750712]]\n",
      "Accuracy:  0.7469230769230769\n",
      "F1 score:  0.8101557991921523\n",
      "Parametro C:  1.0\n",
      "Penalty:  l2\n",
      "[[ 0.09498674 -0.69983987 -0.09296198  0.35488063 -0.08541391  0.30931728\n",
      "  -0.44877682 -0.10069911  0.11740068  0.31640499  1.0202264 ]]\n",
      "Accuracy:  0.7453846153846154\n",
      "F1 score:  0.809001731102135\n"
     ]
    }
   ],
   "source": [
    "C=[ 0.01, 0.1, 1.0]\n",
    "penalty=['l1', 'l2']\n",
    "\n",
    "for c in C:\n",
    "    for p in penalty:\n",
    "        logreg = LogisticRegression(C= c, penalty=p, solver='liblinear')\n",
    "        logreg.fit(X_train_scaled, y_train)\n",
    "        y_pred = logreg.predict(preprocessing.scale(X_test_scaled))  \n",
    "        y_pred_prob = logreg.predict_proba(X_test_scaled)\n",
    "        #print(metrics.log_loss(y_test, y_pred_prob))\n",
    "        print(\"Parametro C: \",c)\n",
    "        print(\"Penalty: \",p)\n",
    "        print(logreg.coef_)\n",
    "        print(\"Accuracy: \",accuracy_score(y_test,y_pred))  \n",
    "        print(\"F1 score: \",f1_score(y_test,y_pred))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que al aplicar regularización en los datos, no solamente cambia la magnitud del peso de las variables sobre la calidad, sino que también cambia la dirección de algunas de estas relaciones. Dentro de las diferentes opciones mostradas en el paso anterior, aquella que genera mejor precisión y f1_score está dada por la combinación C=0.1 y P=l1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
