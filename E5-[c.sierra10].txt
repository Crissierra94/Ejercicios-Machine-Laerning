Tipos de algoritmos de árboles de decisión y sus aplicaciones
El algoritmo CART se basa en árboles de regresión y clasificación, siendo árboles de decisión binaria que se construyen dividiendo en dos ramificaciones repetidamente. En este caso el criterio de decisión para la división es el índice de GINI, y puede ser aplicado cuando la variable dependiente es tanto categórica como numérica.
El algoritmo ID3 (Iterative Dichotomiser 3) realiza la ramificación eligiendo en cada momento el mejor atributo dependiendo de una determinada heurística. Utiliza como criterio de decisión la entropía, que es una medida de incertidumbre del sistema, esto es, arroja la probabilidad de que ocurra cada uno de los posibles resultados, dada una determinada situación.
El algoritmo C4.5 es una extensión del algoritmo ID3, así, usa el concepto de entropía como criterio discriminante para determinar cuál es el mejor atributo para dividir el nodo actual. Este algoritmo puede tratar con variables continuas y discretas, en el primer caso busca el mejor punto de corte basándose en la ganancia de información con lo que genera una división binaria, y en el segundo caso, genera un nodo por cada posible valor del atributo.
El algoritmo CHAID consiste en un algoritmo para la construcción de árboles de decisión basado en el testeo de significancia ajustada. Utiliza el Chi - cuadrado para medir el grado de correlación entre las variables independientes. Solamente puede tratar variables discretas, pero está diseñado para diferenciar variables nominales de las ordinales. En este caso no se aplica una posterior poda del árbol.
El algoritmo QUEST (Quick, Unbiased, Efficient, Statistical Tree) es un método de clasificación binario para generar árboles de decisión, utiliza una secuencia de reglas basada en comprobaciones de significancia para evaluar los campos de entrada de un nodo. Los campos de entrada pueden ser continuos, sin embargo, el campo objetivo debe ser categórico. Todas las divisiones son binarias. 

